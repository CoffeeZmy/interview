# 分布式

## CAP定理

### 概念

在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance），三者往往只能满足两点，不可兼得；

- 一致性：读操作能返回最新的写操作结果；
- 可用性：非故障节点在和合理的时间返回合理的响应，即高可用；
- 分区容错性：当网络出现分区，使得两个节点无法连通时，系统能否继续履行职责；

### C和A的矛盾

- 提高分区容忍性的办法就是把一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里，容忍性就提高了；
- 然而要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的；
- 要保持一致性，就必须在写操作时，每次在等待所有节点写入成功时才认为是成功，这个等待又会带来可用性的问题；

### 对CAP的理解

- 正常情况下是可以做到CA的，但是如果出现网络分区，就必须放弃C和A中的一个。一般我们会保证系统不能挂掉，然后通过同步数据的方式还原C，也可以让我们的系统挂掉一部分，然后通过重启节点的方式还原A；
- 对CAP的选择主要还是看业务场景，如果是搜索之类的功能，短期内的数据不一致不影响使用，可使用AP，如果是后台商品管理，为了避免商品数据的不一致，需要设置为CP，如果是支付功能，为保证其稳定性，需设置为CA（单网络的集群）；

## ID生成方式

可以有以下方式：

**UUID**

- 优点：本地直接生成，生成效率很高；

- 缺点：

  ​	不易于存储，不能作为MySQL的主键（因为聚簇索引）

  ​	基于MAC地址生成的UUID算法可能会造成MAC地址泄露；

**基于数据库**

- 利用数据库的auto_increment属性生成递增的ID，可通过配置多个实例，使用不同的步长来提高系统的可用性；
- 缺点是水平扩展性较差且依赖于数据库；

**基于Redis**

利用Redis的INCR命令可以Key中存储的数字值加1，此操作是原子性的，可以用来生成ID；

- 优点：有序递增，可读性强，性能还可以；
- 缺点：依赖于Redis，需保证Redis高可用，且会占用带宽，需考虑网络延时的问题；

**基于snowflake算法**

snowflake算法：41个bit存储时间戳的差值，10bit存储机器的id，12bit作为毫秒内的序列号，还有一个最高位的符号位为0；

优点：

- ​	每秒可生成百万级数量的id，性能强；
- ​	整个ID呈递增趋势；

缺点：

​	强依赖于机器时钟，如果时钟回拨，会导致重复id生成；

**美团的Leaf方案**

原理大致是每次从数据库获取一个ID区间，区间用完了再获取新的号段（还有一些优化方案）；

## 分布式事务

### XA事务

- XA是一个分布式事务协议，它定义了事务管理器TM和资源管理器RM之间的接口，资源管理器往往由数据库实现；
- XA事务是基于两阶段提交协议实现的，第一阶段TM告知RM准备提交事务，RM会锁住相应资源并回复给TM已准备完毕，第二阶段TM下发提交事务命令，RM各自提交事务，如果失败则不断重试；
- XA事务性能差，且需要考虑事务管理器的可用性问题，一般情况下不会使用；

### TCC方案

TCC是业务层面的分布式事务，即try - confirm - cancel

- try阶段：对各个服务的资源做检测以及对资源进行锁定或预留；
- confirm阶段：在服务中执行实际的操作；
- cancel阶段：如果任何一个服务的业务方法执行出错，则进行回滚；

TCC方案也需要有一个事务管理器，且需要自己处理回滚，一般也很少使用；

### 本地消息表

利用各系统本地事务来实现分布式事务。会有一张存放本地消息的表，在执行业务的时候将业务的执行和将消息放入消息表中的操作放在同一个本地事务。接着去调用下一个操作，如果成功则修改消息表的状态，如果失败则通过后台定时任务读取消息表，筛选出未成功的消息再调用对应的服务。其实现的是最终一致性；

### 基于消息队列

- 基于消息队列实现分布式事务，比如RocketMQ就支持消息事务，其大致原理为：
- 首先发送方给Broker发送prepared消息，如果发送成功了则发送方会执行本地事务，再根据本地事务的结果向Broker发送Commit或Rollback命令。并且发送方会提供一个反查事务状态的接口给Broker，如果到达超时时间，Broker会调用接口反查事务状态，然后执行后续操作；
- 基于消息队列的分布式事务保证的是最终一致性；

### 尽最大努力通知方案

- 系统A本地事务执行完毕后，发送消息到MQ，然后会有一个专门的最大努力通知服务，这个服务消息MQ并写入数据库记录下来，接着调用系统B的接口执行完剩余事务，如果执行失败了则定时重试；
- 适用于对时间不敏感的业务；

### 怎样选择方案

根据业务场景，如果要求强一致性，可以使用TCC方案，一般场景使用基于MQ的分布式事务

## 分布式锁

### 为什么要用分布式锁 / 应用场景

- 在分布式环境中，需要一种跨JVM的**互斥**机制来控制资源的访问；
- 例如为了避免用户操作重读导致交易执行多次，使用分布式锁可以将第一次以外的请求在所有服务节点上立马取消掉。如果使用事务在数据库层面也能进行限制，但是会增大数据库的压力；
- 例如在分布式系统中为了避免同一任务重读执行，某个节点执行任务之后可以使用分布式锁避免其他节点在同一时刻得到任务；

### 如何实现

#### 基于数据库

- 利用数据库的唯一索引的机制实现，在进入同步块时先向表中插入数据，插入成功则视为获得锁，执行完毕后删除对应数据行释放锁；
- 其优点是实现简单，缺点是1.性能较差，2.依赖于数据库（需考虑数据库可用性），3.没有锁失效自动删除机制（超时时间），4.没有阻塞机制，获取锁失败的线程只能通过轮询的方式再次尝试获取锁；

#### 基于Redis

- 利用Redis的SETNX操作（set if not exist），如果key不存在会进行set操作并返回成功，set成功表示获得锁，set失败表示获取锁失败。再加上EX参数可以让该key在超时之后自动删除；

- 其优点是1.吞吐量高，2.有锁失败自动删除机制；

- 缺点是：

  1.Redis单点故障问题；
2.锁超时问题如何解决：如果锁到期但是业务还未执行完如何处理？设置看门狗，定时延长超时时长避免过期。为什么不设置永不超时？为了防范业务，没写解锁方法或发生异常之后无法进行解锁的问题；
  3.轮询获取锁状态的方式很低效；

#### 基于ZooKeeper

- 利用ZooKeeper的临时节点的方式，当客户端对某个方法加锁时，在ZooKeeper上的与该方法对应的指定节点的目录下，生成一个临时有序节点（利用有序节点是为了防止惊群效应，即大量线程竞争锁时，大部分createNode都会失败，并且锁被释放时会触发大量监听器。改进方案就是创建有序节点）；
- 判断该节点是否是当前目录下最小的节点，如果是则获取成功，如果不是，则获取失败，并获取上一个临时有序节点，对该节点进行监听，当节点删除时通知客户端；

优点：1.利用ZooKeeper的监听器机制，避免了获取锁的轮询机制。2.有锁失效自动删除机制（客户端断开连接时，临时节点会被删除），不会死锁；

缺点：1.性能不如Redis；2.强依赖于ZooKeeper；

## 消息队列

### 优缺点

#### 优点 / 为什么使用消息队列

- 减少请求响应时间；
- 服务间解耦，生产者只需要保证消息成功发送到消息队列，不需要关心后续消费者如何处理；
- 流量削峰，对于不需要实时处理的请求，当并发量特别大时，而可以先在消息队列中作缓存，然后陆续发送给对应的服务去处理；

#### 缺点

- 需考虑消息队列的可用性；
- 需考虑消息重复消费、消息丢失，消息传递顺序等问题；

### 消息重复消费问题如何解决

- 在业务上保证对重复消息的消费是幂等的；
- 用日志表记录已处理成功的消息的id；

### 消息丢失问题如何解决

并不是所有应用都需要保证消息不丢失，需根据业务进行评估。如果业务场景确实需要保证消息不丢失，则应该解决这一问题，不同消息队列提供了各自的解决方案，以Kafka为例：

- 在broker端配置多个副本，并且配置最小同步副本数大于1（min.insync.replicas参数大于1）。并且禁止不干净leader选举（unclean.leader.election.enable=false）；
- producer端配置acks参数为all，这样producer发送的消息全部写入到同步副本后，broker才会回复producer消息发送成功。producer端还应该配置retries重试次数，在遇到网络问题时可以重发消息；
- 在consumer端设置手动提交消息偏移量，在业务上确保消息处理完成后再提交偏移量；

### 消息顺序性如何保证

- Kafka同一个分区的消息一定是有序的，可在发送消息时指定消息的key值或分区键，使消息发送到同一个分区；
- 如果要求消息严格有序，可以给消息设置版本号，比如当前已经处理了v5版本的消息，如果收到v3版本的消息，则直接丢弃；

### 如何保证高可用

- Kafka通过冗余的机制实现高可用，每个分区都会配置多个副本，这些副本分布在不同的broker上；
- 这些副本还会选举出一个leader出现，leader为客户端提供服务，follower与leader保持同步；
- 当leader所在的broker宕机时，Kafka会从剩余的副本中选举出新的leader；

## ZooKeeper

### 应用场景

#### 分布式协调

A系统发送一个请求到MQ，然后B系统消费，A系统如何知道B系统的处理结果？A系统发送请求之后可以在ZooKeeper上对某个节点的值注册一个监听器，一旦B系统处理完就修改ZooKeeper那个节点的值，然后A系统就可以收到通知了；

#### 分布式锁

不再赘述

#### 元数据/配置信息管理

可以用作配置信息的管理，Kafka就是通过ZooKeeper来做一些元数据、配置信息的管理的；

#### 用于主从架构 / 高可用

可用于主从架构，通过创建临时节点的方式实现选举，从节点监听这个znode，如果主节点宕机，可以同过ZooKeeper立即感知到，从而选举出新的主节点提供服务；

## 一致性哈希

### 概念

- 分布式缓存中，需要将数据均匀分散到各个节点中。以Redis为例，我们可以对数据的key取hash值，然后对redis的节点数取模，这样就可以实现数据的均匀分布。但是如果其中一台服务器出现故障或者需要扩容时，就需要所有节点和数据重新取模计算，这个代价很高。
- 一致性hash算法则是将所有的哈希值构成一个环，其范围在0 ~ 2^32 - 1，之后将各个节点散列到这个环上，可以用节点的IP、hostname这一的唯一性字段作为key进行hash；
- 再将数据的key使用相同的函数Hash计算出哈希值，由此确定数据在环上的位置，从此位置沿环顺时针查找，遇到的服务器就是数据存储的服务器；

### 容错性和扩展性

- 假设有一台服务器宕机，那么只有此服务器到环空间前一台服务之间的数据会受影响（会被定位到宕机节点的下一个节点）；
- 当新增一个节点时，只有新增节点和它的上一次节点之间的数据会受影响（会被定位到这个新节点）；
- 所以一致性哈希具有较号的容错性和一致性；

### 虚拟节点

- 数据倾斜问题：当服务器节点较少时， 容易因为节点分布不均匀而导致数据分布不均匀（节点分布在很小的范围）；
- 为解决这个问题，一致性哈希算法引入了虚拟节点，将每一个节点都进行多次hash，生成多个节点放置在环上。即每个实际节点对应了环上的多个虚拟节点，虚拟节点是分布均匀的；

## Kafka的工作原理

### 概述

- Kafka是一个分布式消息引擎系统，它的核心架构包含生产者producer、消费者consumer和broker三部分，生产者发送消息到broker，消费者从broker消费消息；
- Kafka的消息通过topic进行分类，为了提高吞吐量，topic又被分为多个分区partition，producer在发送消息时需要指定topic，还可以指定发送到特定的分区；
- consumer端通过订阅topic来消费消息，consumer端会保存其消费消息的偏移量，并且定期提交给Kafka集群。consumer端可以设置consumer group，topic中的每条消息只会被发送到订阅的消费者组的一个消费者实例上；
- Kafka broker通过ZooKeeper进行服务的协调管理，也会保存一些元数据和配置信息在broker上;
- kafka通过冗余的机制来保证高可用，消息会被保存到多个副本，副本被保存在不同的broker上。这些副本有一个leader副本，负责为客户端提供服务，其他副本为follower，用于和leader保持同步。当leader所在的broker宕机时，Kafka会从与leader保持同步的follower副本中快速地选举出新的leader；

### Kafka是怎样做到高吞吐量、低延时的

- 大量使用操作系统页缓存，内存操作速度快且命中率高
- Kafka不直接参与物理I/O操作，而是交由操作系统来完成
- 采用追加（append）写入方式，摒弃了缓慢的磁盘随机读写操作
- 使用以sendfile为代表的零拷贝技术加强网络间的数据传输效率

**零拷贝**：在内核驱动程序处理I/O数据的时候，它不再需要进行上下文的切换，节省了内核缓冲区与用户态应用程序缓冲区之间的数据拷贝，同时它利用直接存储器访问技术（Direct Memory Access，DMA）执行了I/O操作，因此也避免了OS内核缓冲区之间的数据拷贝，因而得名零拷贝；

## redis setnx + expire有什么缺点，如何优化

可能会出现业务还没执行完，但是已经到达过期时间的问题。解决方案是设置看门狗进行监控，在即将过期时如果发现线程还持有锁，则延长一段时间；

## redis的跳表，为什么不用红黑树



## redis集群是怎么实现的