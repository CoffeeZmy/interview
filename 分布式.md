# 分布式

## CAP定理

### 概念

在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance），三者往往只能满足两点，不可兼得；

- 一致性：读操作能返回最新的写操作结果；
- 可用性：非故障节点在和合理的时间返回合理的响应，即高可用；
- 分区容错性：当网络出现分区，使得两个节点无法连通时，系统能否继续履行职责；

### C和A的矛盾

- 提高分区容忍性的办法就是把一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里，容忍性就提高了；
- 然而要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的；
- 要保持一致性，就必须在写操作时，每次在等待所有节点写入成功时才认为是成功，这个等待又会带来可用性的问题；

### 对CAP的理解

- 正常情况下是可以做到CA的，但是如果出现网络分区，就必须放弃C和A中的一个。一般我们会保证系统不能挂掉，然后通过同步数据的方式还原C，也可以让我们的系统挂掉一部分，然后通过重启节点的方式还原A；
- 对CAP的选择主要还是看业务场景，如果是搜索之类的功能，短期内的数据不一致不影响使用，可使用AP，如果是后台商品管理，为了避免商品数据的不一致，需要设置为CP，如果是支付功能，为保证其稳定性，需设置为CA（单网络的集群）；

### Base理论

Basically Available（基本可用）、Soft State（软状态）和Eventually Consistent（最终一致性）；

## ID生成方式

可以有以下方式：

**UUID**

- 优点：本地直接生成，生成效率很高；

- 缺点：

  ​	不易于存储，不能作为MySQL的主键（因为聚簇索引）

  ​	基于MAC地址生成的UUID算法可能会造成MAC地址泄露；

**基于数据库**

- 利用数据库的auto_increment属性生成递增的ID，可通过配置多个实例，使用不同的步长来提高系统的可用性；
- 缺点是水平扩展性较差且依赖于数据库；

**基于Redis**

利用Redis的INCR命令可以Key中存储的数字值加1，此操作是原子性的，可以用来生成ID；

- 优点：有序递增，可读性强，性能还可以；
- 缺点：依赖于Redis，需保证Redis高可用，且会占用带宽，需考虑网络延时的问题；

**基于snowflake算法**

snowflake算法：41个bit存储时间戳的差值，10bit存储机器的id，12bit作为毫秒内的序列号，还有一个最高位的符号位为0；

优点：

- ​	每秒可生成百万级数量的id，性能强；
- ​	整个ID呈递增趋势；

缺点：

​	强依赖于机器时钟，如果时钟回拨，会导致重复id生成；

**美团的Leaf方案**

原理大致是每次从数据库获取一个ID区间，区间用完了再获取新的号段（还有一些优化方案）；

## 分布式事务

### XA事务

- XA是一个分布式事务协议，它定义了事务管理器TM和资源管理器RM之间的接口，资源管理器往往由数据库实现；
- XA事务是基于两阶段提交协议实现的，第一阶段TM告知RM准备提交事务，RM会锁住相应资源并回复给TM已准备完毕，第二阶段TM下发提交事务命令，RM各自提交事务，如果失败则不断重试；
- XA事务性能差，且需要考虑事务管理器的可用性问题，一般情况下不会使用；

### TCC（Try Confirm Cancel）方案

- Try阶段：对各个服务的资源做检测以及对资源进行锁定或预留；
- Confirm阶段：在各个服务中执行实际的事务操作；
- Cancel阶段：如果任何一个服务的业务方法执行出错，则回滚其他已成功的操作；

与XA事务一样也需要一个事务管理器TM，通常认为只要Try成功则Confirm / Cancel一定成功（如果失败要进行重试）；

TCC是强一致性的分布式事务；

### 本地消息表

- A系统在本地提交事务的同时，插入一条消息M1到消息表；
- 接着A系统将这条消息M1发送到MQ；
- B系统通过MQ接收到消息M1后在一个事务里往本地消息表插入消息M2，并执行其他业务操作，如果发现MQ已经被处理过了则回滚事务，保证不会重复消费；
- 如果B执行成功了，则更新本地消息表中M1和M2的状态；
- 如果B系统处理失败了，则不会更新，A系统会定时扫描自己的消息表，如果有未被B处理成功的消息，则会再次发送到MQ中；

### RocketMQ

- A系统发送一个prepared消息到MQ，告诉B消息我要提交事务了；
- 如果发送成功，则A执行本地事务，如果执行成功，则发送Commit消息到MQ，如果失败则发送Rollback消息；
- 如果B系统收到Commit消息，则执行本地的事务。如果B的本地事务执行失败，则重试或者想办法通知A回滚（看场景）；
- MQ会自动定时轮询所有prepared消息回调A的接口，确认A的本地事务的执行结果。这是为了避免本地事务执行成功了，但是消息却发送失败了的情况；

### 最大努力通知方案

- A的本地事务执行完之后，发送消息到MQ；
- 这里会有一个专门消息MQ的最大努力通知服务，这个服务会消费MQ然后写入数据库中记录下来，接口调用B的接口；
- 如果B执行成功则OK，如果执行失败，则尝试重试，超过一定次数后可以考虑报警人工处理；

### 怎样选择方案

根据业务场景，如果要求强一致性，可以使用TCC方案，一般场景使用基于MQ的分布式事务

## 分布式锁

### 为什么要用分布式锁 / 应用场景

- 在分布式环境中，需要一种跨JVM的**互斥**机制来控制资源的访问；
- 例如为了避免用户操作重读导致交易执行多次，使用分布式锁可以将第一次以外的请求在所有服务节点上立马取消掉。如果使用事务在数据库层面也能进行限制，但是会增大数据库的压力；
- 例如在分布式系统中为了避免同一任务重读执行，某个节点执行任务之后可以使用分布式锁避免其他节点在同一时刻得到任务；

### 如何实现

#### 基于数据库

- 利用数据库的唯一索引的机制实现，在进入同步块时先向表中插入数据，插入成功则视为获得锁，执行完毕后删除对应数据行释放锁；
- 其优点是实现简单，缺点是1.性能较差，2.依赖于数据库（需考虑数据库可用性），3.没有锁失效自动删除机制（超时时间），4.没有阻塞机制，获取锁失败的线程只能通过轮询的方式再次尝试获取锁；

#### 基于Redis

- 利用Redis的SETNX操作（set if not exist），如果key不存在会进行set操作并返回成功，set成功表示获得锁，set失败表示获取锁失败。再加上EX参数可以让该key在超时之后自动删除；

- 其优点是1.吞吐量高，2.有锁失败自动删除机制；

- 缺点是：

  1.Redis单点故障问题；
2.锁超时问题如何解决：如果锁到期但是业务还未执行完如何处理？设置看门狗，定时延长超时时长避免过期。为什么不设置永不超时？为了防范业务，没写解锁方法或发生异常之后无法进行解锁的问题；
  3.轮询获取锁状态的方式很低效；

#### 基于ZooKeeper

- 利用ZooKeeper的临时节点的方式，当客户端对某个方法加锁时，在ZooKeeper上的与该方法对应的指定节点的目录下，生成一个临时有序节点（利用有序节点是为了防止惊群效应，即大量线程竞争锁时，大部分createNode都会失败，并且锁被释放时会触发大量监听器。改进方案就是创建有序节点）；
- 判断该节点是否是当前目录下最小的节点，如果是则获取成功，如果不是，则获取失败，并获取上一个临时有序节点，对该节点进行监听，当节点删除时通知客户端；

优点：1.利用ZooKeeper的监听器机制，避免了获取锁的轮询机制。2.有锁失效自动删除机制（客户端断开连接时，临时节点会被删除），不会死锁；

缺点：1.性能不如Redis；2.强依赖于ZooKeeper；

## 消息队列

### 优缺点

#### 优点 / 为什么使用消息队列

- 减少请求响应时间；
- 服务间解耦，生产者只需要保证消息成功发送到消息队列，不需要关心后续消费者如何处理；
- 流量削峰，对于不需要实时处理的请求，当并发量特别大时，而可以先在消息队列中作缓存，然后陆续发送给对应的服务去处理；

#### 缺点

- 需考虑消息队列的可用性；
- 需考虑消息重复消费、消息丢失，消息传递顺序等问题；

### 消息重复消费问题如何解决

- 在业务上保证对重复消息的消费是幂等的；
- 用日志表记录已处理成功的消息的id；

### 消息丢失问题如何解决

并不是所有应用都需要保证消息不丢失，需根据业务进行评估。如果业务场景确实需要保证消息不丢失，则应该解决这一问题，不同消息队列提供了各自的解决方案，以Kafka为例：

- 在broker端配置多个副本，并且配置最小同步副本数大于1（min.insync.replicas参数大于1）。并且禁止不干净leader选举（unclean.leader.election.enable=false）；
- producer端配置acks参数为all，这样producer发送的消息全部写入到同步副本后，broker才会回复producer消息发送成功。producer端还应该配置retries重试次数，在遇到网络问题时可以重发消息；
- 在consumer端设置手动提交消息偏移量，在业务上确保消息处理完成后再提交偏移量；

### 消息顺序性如何保证

- Kafka同一个分区的消息一定是有序的，可在发送消息时指定消息的key值或分区键，使消息发送到同一个分区；
- 如果要求消息严格有序，可以给消息设置版本号，比如当前已经处理了v5版本的消息，如果收到v3版本的消息，则直接丢弃；

### 如何保证高可用

- Kafka通过冗余的机制实现高可用，每个分区都会配置多个副本，这些副本分布在不同的broker上；
- 这些副本还会选举出一个leader出现，leader为客户端提供服务，follower与leader保持同步；
- 当leader所在的broker宕机时，Kafka会从剩余的副本中选举出新的leader；

## ZooKeeper

### 应用场景

#### 分布式协调

A系统发送一个请求到MQ，然后B系统消费，A系统如何知道B系统的处理结果？A系统发送请求之后可以在ZooKeeper上对某个节点的值注册一个监听器，一旦B系统处理完就修改ZooKeeper那个节点的值，然后A系统就可以收到通知了；

#### 分布式锁

不再赘述

#### 元数据/配置信息管理

可以用作配置信息的管理，Kafka就是通过ZooKeeper来做一些元数据、配置信息的管理的；

#### 用于主从架构 / 高可用

可用于主从架构，通过创建临时节点的方式实现选举，从节点监听这个znode，如果主节点宕机，可以同过ZooKeeper立即感知到，从而选举出新的主节点提供服务；

## 一致性哈希

### 概念

- 分布式缓存中，需要将数据均匀分散到各个节点中。以Redis为例，我们可以对数据的key取hash值，然后对redis的节点数取模，这样就可以实现数据的均匀分布。但是如果其中一台服务器出现故障或者需要扩容时，就需要所有节点和数据重新取模计算，这个代价很高。
- 一致性hash算法则是将所有的哈希值构成一个环，其范围在0 ~ 2^32 - 1，之后将各个节点散列到这个环上，可以用节点的IP、hostname这一的唯一性字段作为key进行hash；
- 再将数据的key使用相同的函数Hash计算出哈希值，由此确定数据在环上的位置，从此位置沿环顺时针查找，遇到的服务器就是数据存储的服务器；

### 容错性和扩展性

- 假设有一台服务器宕机，那么只有此服务器到环空间前一台服务之间的数据会受影响（会被定位到宕机节点的下一个节点）；
- 当新增一个节点时，只有新增节点和它的上一次节点之间的数据会受影响（会被定位到这个新节点）；
- 所以一致性哈希具有较号的容错性和一致性；

### 虚拟节点

- 数据倾斜问题：当服务器节点较少时， 容易因为节点分布不均匀而导致数据分布不均匀（节点分布在很小的范围）；
- 为解决这个问题，一致性哈希算法引入了虚拟节点，将每一个节点都进行多次hash，生成多个节点放置在环上。即每个实际节点对应了环上的多个虚拟节点，虚拟节点是分布均匀的；

## Kafka的工作原理

### 概述

- Kafka是一个分布式消息引擎系统，它的核心架构包含生产者producer、消费者consumer和broker三部分，生产者发送消息到broker，消费者从broker消费消息；
- Kafka的消息通过topic进行分类，为了提高吞吐量，topic又被分为多个分区partition，producer在发送消息时需要指定topic，还可以指定发送到特定的分区；
- consumer端通过订阅topic来消费消息，consumer端会保存其消费消息的偏移量，并且定期提交给Kafka集群。consumer端可以设置consumer group，topic中的每条消息只会被发送到订阅的消费者组的一个消费者实例上；
- Kafka broker通过ZooKeeper进行服务的协调管理，也会保存一些元数据和配置信息在broker上;
- kafka通过冗余的机制来保证高可用，消息会被保存到多个副本，副本被保存在不同的broker上。这些副本有一个leader副本，负责为客户端提供服务，其他副本为follower，用于和leader保持同步。当leader所在的broker宕机时，Kafka会从与leader保持同步的follower副本中快速地选举出新的leader；

### Kafka是怎样做到高吞吐量、低延时的

- 大量使用操作系统页缓存，内存操作速度快且命中率高
- Kafka不直接参与物理I/O操作，而是交由操作系统来完成
- 采用追加（append）写入方式，摒弃了缓慢的磁盘随机读写操作
- 使用以sendfile为代表的零拷贝技术加强网络间的数据传输效率

**零拷贝**：在内核驱动程序处理I/O数据的时候，它不再需要进行上下文的切换，节省了内核缓冲区与用户态应用程序缓冲区之间的数据拷贝，同时它利用直接存储器访问技术（Direct Memory Access，DMA）执行了I/O操作，因此也避免了OS内核缓冲区之间的数据拷贝，因而得名零拷贝；

## Redis

### 跳跃表

- Redis的zset，在包含元素较多或包含的元素较大时就会使用跳跃表来实现；
- 跳跃可以理解为是具有多级索引结构的链表，每个链表节点都包含一个数组的层结构，每层都包含了指向下一个节点的指针和当前节点与指向节点的距离；
- 在进行查询操作时都可以通过层结构跳过一部分节点，从而提高查询效率，它的查询的时间复杂度为O(logN)；

#### 为什么用跳跃表，而不是红黑树

- 跳跃表实现上比红黑树简单（作者的回答）；
- 便于区间查找，先O(logN)找到首节点，然后forward，而红黑树需要中序遍历；

### 压缩列表

- 当一个列表（哈希）只包含少量元素（键值对）且列表项（键值对的键和值）要么是整数项，要么是比较短的字符串时，Redis就会使用压缩列表来做列表的底层实现；
- 压缩列表每个节点都可以保存长度不定的字节数组或整数值，并且会保存上一个节点的长度，这样就可以根据当前节点的起始地址获取上一个节点的起始地址，从而实现压缩列表从后往前遍历；

#### 压缩列表的好处

- 每个节点长度不定，节省了空间；
- 利用了连续的内存块，可以更快地被载入到缓存中；

### 集群

#### 主从模式

- 用一个redis实例作为主机，其余实例作为从机，主机和从机的数据完全一致，主机支持数据的读写和各项操作，从机只支持与主机的数据同步和读取。因而可以将写入数据的命令发送给主机执行，读取数据的命令发送给不同的从机执行，从而达到读写分离的目的；
- 该模式的问题是如果redis实例挂掉，没有提供一定的手段通知客户端另外可连接的客户端地址，因而需要手动更改客户端配置重新连接；

#### 哨兵模式

Sentinel节点定期监控发现主节点是否出现故障，当主节点出现故障时，由Redis Sentinel自动完成故障发现和转移，并通知应用方，实现高可用性；

#### 集群模式

- redis主从或哨兵模式的每个实例都是全量存储所有数据，浪费内存且有木桶效应（即短板效应，可用内存等于内存最小的那台实例的可用内存）。为了最大利用内存，可以采用集群模式。集群将数据分片存储，每组节点存储一部分数据，从而达到分布式集群的目的；
- redis集群中数据是和槽挂钩的，其总共定义了16384（2的14次方）个槽，所有的数据根据一致性哈希算法映射到这些槽中，且这些槽是按照设置被分配到不同的redis节点上的；
- 集群模式会直接导致访问数据方式的改变，比如客户端向A节点发送GET命令但该数据在B节点，redis会返回重定向错误给客户端让客户端再次发送请求，这也导致了必须在相同的节点才能执行的一些高级功能无法使用（Lua、事务、Pipeline）；

#### 如何选择

- 集群的优势在于高可用，将写操作分开到不同的节点，如果写的操作较多且数据量巨大，且不需要高级功能则可能考虑集群；
- 哨兵模式优势在于高可用，支持高级功能，且能在读的操作较多的场景下工作，所以在绝大多数场景中是适合的；
- 主从的优势在于支持高级功能，且能在读的操作较多的场景下工作，但无法保证高可用，不建议在数据要求严格的场景下使用；

### 持久化

- RDB（快照）持久化可以在指定的时间间隔内生成数据集的时间点快照（point-int-time snapshot）；
- AOF持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。AOF文件中的命令全部以Redis协议的格式来保存，新命令会被追加到文件的末尾。Redis还可以在后台对AOF文件进行重写，使得AOF文件的体积不会超出保存数据集状态所需的实际大小；
- Redis还可以同时使用AOF持久化和RDB持久化，这种情况下，Redis重启时会优先使用AOF文件来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整；
- 持久化会对Redis的性能造成非常严重的影响，如果一定需要保存数据，应该使用数据库，所以Redis的持久化意义不大；

### redis setnx + expire有什么缺点，如何优化

可能会出现业务还没执行完，但是已经到达过期时间的问题。解决方案是设置看门狗进行监控，在即将过期时如果发现线程还持有锁，则延长一段时间；

## 缓存

### 使用策略

#### 延迟加载

- 读：当读请求到来时，先从缓存读，如果读不到就从数据库读，读完之后同步到缓存且添加过期时间；
- 写：当写请求到来时，只写数据库；
- 优点：仅对请求的数据进行一段时间的缓存，没有请求过的数据就不会被缓存，节省了缓存空间，节点出现故障不是致命的，因为可以从数据库中得到；
- 缺点：缓存数据不是最新的，且有缓存击穿和缓存失效的问题；

#### 直写

- 读：当读请求到来时，先从缓存读，如果读不到就从数据库读，读完后同步到缓存且设置为永不过期；
- 写：当写请求到来时，先写数据库再同步到缓存，设置永不过期；
- 优点：缓存数据是最新的，无须担心缓存击穿、失效问题，编码方便；
- 缺点：大量数据可能没有被读取的造成资源浪费，如果节点故障或重启会导致缓存数据的丢失直到有些操作同步到缓存。每次写入都需要写缓存导致的性能损失；
- 永不过期的缓存会占用大量空间，可以设置过期时间来改进，但是会引用缓存失效问题，需注意解决；

#### 如何选择

- 如果需要缓存与数据库数据保持实时一致，则需要选择直写方式；
- 如果缓存服务很稳定，可用空间大，写缓存的性能丢失能够接收，选择直写方式比较方便实现。否则选择延迟加载，同时注意解决缓存失效的问题；

### 缓存问题

#### 缓存击穿

- 查询一个数据库中不存在的数据，比如输入一个不存在的ID，导致每次都会请求都会访问DB，如果有人恶意破坏，很可能对DB造成过大的压力；
- 解决办法：当通过某个key去查询数据时，如果数据库中查询不到，则将此key对应的value设置为一个默认的值；

#### 缓存失效

- 高并发环境下，如果key对应的缓存失效，此时会有多个进程同时查询DB，然后再去同时设置缓存，如果这个key是系统中的热点key或同事失效的数量比较多时，DB访问量会瞬间增大，造成过大的压力；
- 解决办法：将系统中key的缓存失效时间均匀地错开；

#### 热点key

- 缓存中地某些key对应的value存储在集群中的一台，使其所有流量涌向同一机器，成为系统的瓶颈，该问题的挑战在于它无法通过增加机器容量来解决；
- 客户端热点key缓存：将热点key对应value缓存在客户端本地，并设置一个失效时间；
- 将热点key分散为多个子key，然后存储到缓存集群的不同机器上，这些子key对应的value都和热点key是一样的；

### 缓存淘汰策略

- **LFU（Least Frequently Used，最不经常使用算法）**：淘汰最低访问数的条目，并不经常使用，因为无法淘汰一个拥有最初高访问率之后长时间没有被访问的条目；
- **LRU（Least Recently Used，最近最少使用算法）**：将最近使用的条目放到靠近缓存顶部的位置，当缓存达到极限时，会从缓存底部开始移除缓存。当存在热点数据时，LRU的效率很好，但是偶发性、周期性的批量操作会导致LRU命中率急剧下降、缓存污染情况比较严重；
- **FIFO（先进先出算法）**：顺序写入数据、顺序读出数据；
- **ARC（Adjustable Replacement Cache，自适应缓存替换算法）**：同时跟踪记录LFU和LRU；
- **MRU（Most Recently Used，最近最常使用算法）**：最先移除最近最常使用的条目，擅长处理一个条目越久，越容易被访问，如果的情况；

